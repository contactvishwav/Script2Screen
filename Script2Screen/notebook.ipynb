{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_columns', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>title</th>\n",
       "      <th>vote_average</th>\n",
       "      <th>vote_count</th>\n",
       "      <th>status</th>\n",
       "      <th>release_date</th>\n",
       "      <th>revenue</th>\n",
       "      <th>runtime</th>\n",
       "      <th>adult</th>\n",
       "      <th>backdrop_path</th>\n",
       "      <th>budget</th>\n",
       "      <th>homepage</th>\n",
       "      <th>imdb_id</th>\n",
       "      <th>original_language</th>\n",
       "      <th>original_title</th>\n",
       "      <th>overview</th>\n",
       "      <th>popularity</th>\n",
       "      <th>poster_path</th>\n",
       "      <th>tagline</th>\n",
       "      <th>genres</th>\n",
       "      <th>production_companies</th>\n",
       "      <th>production_countries</th>\n",
       "      <th>spoken_languages</th>\n",
       "      <th>keywords</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>27205</td>\n",
       "      <td>Inception</td>\n",
       "      <td>8.364</td>\n",
       "      <td>34495</td>\n",
       "      <td>Released</td>\n",
       "      <td>2010-07-15</td>\n",
       "      <td>825532764</td>\n",
       "      <td>148</td>\n",
       "      <td>False</td>\n",
       "      <td>/8ZTVqvKDQ8emSGUEMjsS4yHAwrp.jpg</td>\n",
       "      <td>160000000</td>\n",
       "      <td>https://www.warnerbros.com/movies/inception</td>\n",
       "      <td>tt1375666</td>\n",
       "      <td>en</td>\n",
       "      <td>Inception</td>\n",
       "      <td>Cobb, a skilled thief who commits corporate es...</td>\n",
       "      <td>83.952</td>\n",
       "      <td>/oYuLEt3zVCKq57qu2F8dT7NIa6f.jpg</td>\n",
       "      <td>Your mind is the scene of the crime.</td>\n",
       "      <td>Action, Science Fiction, Adventure</td>\n",
       "      <td>Legendary Pictures, Syncopy, Warner Bros. Pict...</td>\n",
       "      <td>United Kingdom, United States of America</td>\n",
       "      <td>English, French, Japanese, Swahili</td>\n",
       "      <td>rescue, mission, dream, airplane, paris, franc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>157336</td>\n",
       "      <td>Interstellar</td>\n",
       "      <td>8.417</td>\n",
       "      <td>32571</td>\n",
       "      <td>Released</td>\n",
       "      <td>2014-11-05</td>\n",
       "      <td>701729206</td>\n",
       "      <td>169</td>\n",
       "      <td>False</td>\n",
       "      <td>/pbrkL804c8yAv3zBZR4QPEafpAR.jpg</td>\n",
       "      <td>165000000</td>\n",
       "      <td>http://www.interstellarmovie.net/</td>\n",
       "      <td>tt0816692</td>\n",
       "      <td>en</td>\n",
       "      <td>Interstellar</td>\n",
       "      <td>The adventures of a group of explorers who mak...</td>\n",
       "      <td>140.241</td>\n",
       "      <td>/gEU2QniE6E77NI6lCU6MxlNBvIx.jpg</td>\n",
       "      <td>Mankind was born on Earth. It was never meant ...</td>\n",
       "      <td>Adventure, Drama, Science Fiction</td>\n",
       "      <td>Legendary Pictures, Syncopy, Lynda Obst Produc...</td>\n",
       "      <td>United Kingdom, United States of America</td>\n",
       "      <td>English</td>\n",
       "      <td>rescue, future, spacecraft, race against time,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>155</td>\n",
       "      <td>The Dark Knight</td>\n",
       "      <td>8.512</td>\n",
       "      <td>30619</td>\n",
       "      <td>Released</td>\n",
       "      <td>2008-07-16</td>\n",
       "      <td>1004558444</td>\n",
       "      <td>152</td>\n",
       "      <td>False</td>\n",
       "      <td>/nMKdUUepR0i5zn0y1T4CsSB5chy.jpg</td>\n",
       "      <td>185000000</td>\n",
       "      <td>https://www.warnerbros.com/movies/dark-knight/</td>\n",
       "      <td>tt0468569</td>\n",
       "      <td>en</td>\n",
       "      <td>The Dark Knight</td>\n",
       "      <td>Batman raises the stakes in his war on crime. ...</td>\n",
       "      <td>130.643</td>\n",
       "      <td>/qJ2tW6WMUDux911r6m7haRef0WH.jpg</td>\n",
       "      <td>Welcome to a world without rules.</td>\n",
       "      <td>Drama, Action, Crime, Thriller</td>\n",
       "      <td>DC Comics, Legendary Pictures, Syncopy, Isobel...</td>\n",
       "      <td>United Kingdom, United States of America</td>\n",
       "      <td>English, Mandarin</td>\n",
       "      <td>joker, sadism, chaos, secret identity, crime f...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>19995</td>\n",
       "      <td>Avatar</td>\n",
       "      <td>7.573</td>\n",
       "      <td>29815</td>\n",
       "      <td>Released</td>\n",
       "      <td>2009-12-15</td>\n",
       "      <td>2923706026</td>\n",
       "      <td>162</td>\n",
       "      <td>False</td>\n",
       "      <td>/vL5LR6WdxWPjLPFRLe133jXWsh5.jpg</td>\n",
       "      <td>237000000</td>\n",
       "      <td>https://www.avatar.com/movies/avatar</td>\n",
       "      <td>tt0499549</td>\n",
       "      <td>en</td>\n",
       "      <td>Avatar</td>\n",
       "      <td>In the 22nd century, a paraplegic Marine is di...</td>\n",
       "      <td>79.932</td>\n",
       "      <td>/kyeqWdyUXW608qlYkRqosgbbJyK.jpg</td>\n",
       "      <td>Enter the world of Pandora.</td>\n",
       "      <td>Action, Adventure, Fantasy, Science Fiction</td>\n",
       "      <td>Dune Entertainment, Lightstorm Entertainment, ...</td>\n",
       "      <td>United States of America, United Kingdom</td>\n",
       "      <td>English, Spanish</td>\n",
       "      <td>future, society, culture clash, space travel, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>24428</td>\n",
       "      <td>The Avengers</td>\n",
       "      <td>7.710</td>\n",
       "      <td>29166</td>\n",
       "      <td>Released</td>\n",
       "      <td>2012-04-25</td>\n",
       "      <td>1518815515</td>\n",
       "      <td>143</td>\n",
       "      <td>False</td>\n",
       "      <td>/9BBTo63ANSmhC4e6r62OJFuK2GL.jpg</td>\n",
       "      <td>220000000</td>\n",
       "      <td>https://www.marvel.com/movies/the-avengers</td>\n",
       "      <td>tt0848228</td>\n",
       "      <td>en</td>\n",
       "      <td>The Avengers</td>\n",
       "      <td>When an unexpected enemy emerges and threatens...</td>\n",
       "      <td>98.082</td>\n",
       "      <td>/RYMX2wcKCBAr24UyPD7xwmjaTn.jpg</td>\n",
       "      <td>Some assembly required.</td>\n",
       "      <td>Science Fiction, Action, Adventure</td>\n",
       "      <td>Marvel Studios</td>\n",
       "      <td>United States of America</td>\n",
       "      <td>English, Hindi, Russian</td>\n",
       "      <td>new york city, superhero, shield, based on com...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       id            title  vote_average  vote_count    status release_date  \\\n",
       "0   27205        Inception         8.364       34495  Released   2010-07-15   \n",
       "1  157336     Interstellar         8.417       32571  Released   2014-11-05   \n",
       "2     155  The Dark Knight         8.512       30619  Released   2008-07-16   \n",
       "3   19995           Avatar         7.573       29815  Released   2009-12-15   \n",
       "4   24428     The Avengers         7.710       29166  Released   2012-04-25   \n",
       "\n",
       "      revenue  runtime  adult                     backdrop_path     budget  \\\n",
       "0   825532764      148  False  /8ZTVqvKDQ8emSGUEMjsS4yHAwrp.jpg  160000000   \n",
       "1   701729206      169  False  /pbrkL804c8yAv3zBZR4QPEafpAR.jpg  165000000   \n",
       "2  1004558444      152  False  /nMKdUUepR0i5zn0y1T4CsSB5chy.jpg  185000000   \n",
       "3  2923706026      162  False  /vL5LR6WdxWPjLPFRLe133jXWsh5.jpg  237000000   \n",
       "4  1518815515      143  False  /9BBTo63ANSmhC4e6r62OJFuK2GL.jpg  220000000   \n",
       "\n",
       "                                         homepage    imdb_id  \\\n",
       "0     https://www.warnerbros.com/movies/inception  tt1375666   \n",
       "1               http://www.interstellarmovie.net/  tt0816692   \n",
       "2  https://www.warnerbros.com/movies/dark-knight/  tt0468569   \n",
       "3            https://www.avatar.com/movies/avatar  tt0499549   \n",
       "4      https://www.marvel.com/movies/the-avengers  tt0848228   \n",
       "\n",
       "  original_language   original_title  \\\n",
       "0                en        Inception   \n",
       "1                en     Interstellar   \n",
       "2                en  The Dark Knight   \n",
       "3                en           Avatar   \n",
       "4                en     The Avengers   \n",
       "\n",
       "                                            overview  popularity  \\\n",
       "0  Cobb, a skilled thief who commits corporate es...      83.952   \n",
       "1  The adventures of a group of explorers who mak...     140.241   \n",
       "2  Batman raises the stakes in his war on crime. ...     130.643   \n",
       "3  In the 22nd century, a paraplegic Marine is di...      79.932   \n",
       "4  When an unexpected enemy emerges and threatens...      98.082   \n",
       "\n",
       "                        poster_path  \\\n",
       "0  /oYuLEt3zVCKq57qu2F8dT7NIa6f.jpg   \n",
       "1  /gEU2QniE6E77NI6lCU6MxlNBvIx.jpg   \n",
       "2  /qJ2tW6WMUDux911r6m7haRef0WH.jpg   \n",
       "3  /kyeqWdyUXW608qlYkRqosgbbJyK.jpg   \n",
       "4   /RYMX2wcKCBAr24UyPD7xwmjaTn.jpg   \n",
       "\n",
       "                                             tagline  \\\n",
       "0               Your mind is the scene of the crime.   \n",
       "1  Mankind was born on Earth. It was never meant ...   \n",
       "2                  Welcome to a world without rules.   \n",
       "3                        Enter the world of Pandora.   \n",
       "4                            Some assembly required.   \n",
       "\n",
       "                                        genres  \\\n",
       "0           Action, Science Fiction, Adventure   \n",
       "1            Adventure, Drama, Science Fiction   \n",
       "2               Drama, Action, Crime, Thriller   \n",
       "3  Action, Adventure, Fantasy, Science Fiction   \n",
       "4           Science Fiction, Action, Adventure   \n",
       "\n",
       "                                production_companies  \\\n",
       "0  Legendary Pictures, Syncopy, Warner Bros. Pict...   \n",
       "1  Legendary Pictures, Syncopy, Lynda Obst Produc...   \n",
       "2  DC Comics, Legendary Pictures, Syncopy, Isobel...   \n",
       "3  Dune Entertainment, Lightstorm Entertainment, ...   \n",
       "4                                     Marvel Studios   \n",
       "\n",
       "                       production_countries  \\\n",
       "0  United Kingdom, United States of America   \n",
       "1  United Kingdom, United States of America   \n",
       "2  United Kingdom, United States of America   \n",
       "3  United States of America, United Kingdom   \n",
       "4                  United States of America   \n",
       "\n",
       "                     spoken_languages  \\\n",
       "0  English, French, Japanese, Swahili   \n",
       "1                             English   \n",
       "2                   English, Mandarin   \n",
       "3                    English, Spanish   \n",
       "4             English, Hindi, Russian   \n",
       "\n",
       "                                            keywords  \n",
       "0  rescue, mission, dream, airplane, paris, franc...  \n",
       "1  rescue, future, spacecraft, race against time,...  \n",
       "2  joker, sadism, chaos, secret identity, crime f...  \n",
       "3  future, society, culture clash, space travel, ...  \n",
       "4  new york city, superhero, shield, based on com...  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tmdb = pd.read_csv('../../Downloads/raw_tmdb.csv')\n",
    "tmdb.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# removed movies that are unreleased\n",
    "tmdb = tmdb[tmdb['status'] == 'Released']\n",
    "# remove movies that do not have a description\n",
    "tmdb = tmdb[tmdb['overview'].notna()]\n",
    "# change dates to pandas datetime format\n",
    "tmdb['release_date'] = pd.to_datetime(tmdb['release_date'])\n",
    "# original language is english\n",
    "tmdb = tmdb[tmdb['original_language'] == 'en']\n",
    "# drop columns\n",
    "tmdb = tmdb.drop(columns = ['backdrop_path', 'homepage', 'original_title', 'poster_path', 'tagline', 'spoken_languages', 'original_language', 'status'])\n",
    "# insert release_year\n",
    "years = tmdb['release_date'].dt.year\n",
    "tmdb.insert(4, 'release_year', years)\n",
    "# insert profit\n",
    "tmdb.insert(9, 'profit', tmdb['revenue'] - tmdb['budget'])\n",
    "# remove 0 budget movies\n",
    "tmdb = tmdb[tmdb['budget'] != 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop movies without title\n",
    "tmdb = tmdb[tmdb['title'].notna()]\n",
    "# drop movies without runtimes\n",
    "tmdb = tmdb[tmdb['runtime'] != 0]\n",
    "# drop movies without release date\n",
    "tmdb = tmdb[tmdb['release_date'].notna()]\n",
    "# convert release_year to int\n",
    "tmdb['release_year'] = tmdb['release_year'].astype(int)\n",
    "# rename popularity to tmdb_popularity\n",
    "tmdb = tmdb.rename(columns={'popularity': 'tmdb_popularity'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reset index\n",
    "tmdb = tmdb.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmdb_rev = tmdb[tmdb['revenue'] != 0]\n",
    "tmdb_rev.to_csv('./data/tmdb_rev.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pandas as pd\n",
    "# import os\n",
    "# import numpy as np\n",
    "# from sklearn.model_selection import train_test_split\n",
    "# from sklearn.metrics import mean_absolute_error, r2_score\n",
    "# from lightgbm import LGBMRegressor\n",
    "# from sentence_transformers import SentenceTransformer\n",
    "# import pickle\n",
    "# from sklearn.decomposition import PCA\n",
    "\n",
    "# # --- Load and preprocess data ---\n",
    "# print(\"Loading data...\")\n",
    "# df = pd.read_csv('./data/tmdb_rev.csv')\n",
    "# df = df.dropna(subset=['overview', 'budget', 'release_year', 'revenue', 'title'])\n",
    "\n",
    "# df['overview'] = df['overview'].fillna(\"\")\n",
    "# df['budget'] = df['budget'].fillna(0)\n",
    "# df['release_year'] = df['release_year'].fillna(0)\n",
    "# df['revenue'] = df['revenue'].fillna(0)\n",
    "\n",
    "# # --- Get overview embeddings in batches ---\n",
    "# print(\"Generating embeddings...\")\n",
    "# bert = SentenceTransformer('all-MiniLM-L6-v2')\n",
    "# batch_size = 100\n",
    "# overview_embeddings = []\n",
    "# for i in range(0, len(df), batch_size):\n",
    "#     batch = df['overview'].iloc[i:i+batch_size].tolist()\n",
    "#     overview_embeddings.append(bert.encode(batch, show_progress_bar=True))\n",
    "# overview_embeddings = np.vstack(overview_embeddings)\n",
    "\n",
    "# # Reduce dimensionality\n",
    "# print(\"Reducing dimensions...\")\n",
    "# pca = PCA(n_components=100)\n",
    "# overview_embeddings = pca.fit_transform(overview_embeddings)\n",
    "\n",
    "# # --- Features ---\n",
    "# X = np.hstack([\n",
    "#     overview_embeddings,\n",
    "#     df[['budget', 'release_year']].values\n",
    "# ])\n",
    "# y = np.log1p(df['revenue'].values)  # Log transform for better performance\n",
    "\n",
    "# print(f\"Final data shape - X: {X.shape}, y: {y.shape}\")\n",
    "\n",
    "# # --- Split & train ---\n",
    "# print(\"Training model...\")\n",
    "# X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# model = LGBMRegressor(\n",
    "#     n_estimators=200,\n",
    "#     random_state=42,\n",
    "#     max_depth=5,\n",
    "#     num_leaves=20,\n",
    "#     subsample=0.8,\n",
    "#     colsample_bytree=0.8\n",
    "# )\n",
    "# model.fit(X_train, y_train)\n",
    "\n",
    "# # --- Make predictions ---\n",
    "# y_pred = model.predict(X_test)\n",
    "\n",
    "# # --- Evaluate the model ---\n",
    "# mae = mean_absolute_error(np.expm1(y_test), np.expm1(y_pred))\n",
    "# r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "# # --- Print the results ---\n",
    "# print(f\"Mean Absolute Error (MAE): ${mae:,.2f}\")\n",
    "# print(f\"R-squared (R²): {r2:.4f}\")\n",
    "\n",
    "# # --- Save the model and embeddings ---\n",
    "# os.makedirs(\"models\", exist_ok=True)\n",
    "\n",
    "# with open(\"models/revenue_model.pkl\", \"wb\") as f:\n",
    "#     pickle.dump(model, f)\n",
    "\n",
    "# with open(\"models/bert_model.pkl\", \"wb\") as f:\n",
    "#     pickle.dump(bert, f)\n",
    "\n",
    "# df[['title', 'overview']].to_csv(\"models/title_reference.csv\", index=False)\n",
    "# np.save(\"models/overview_embeddings.npy\", overview_embeddings)\n",
    "\n",
    "# print(\"✅ Model training complete and saved.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pandas as pd\n",
    "# import os\n",
    "# import numpy as np\n",
    "# from sklearn.model_selection import train_test_split\n",
    "# from sklearn.metrics import mean_absolute_error, r2_score\n",
    "# from lightgbm import LGBMRegressor\n",
    "# from sentence_transformers import SentenceTransformer\n",
    "# import pickle\n",
    "# from sklearn.decomposition import PCA\n",
    "# import gc  # Garbage collector\n",
    "\n",
    "# def safe_embedding_generation(texts, model, batch_size=50):\n",
    "#     \"\"\"Generate embeddings with memory safety\"\"\"\n",
    "#     embeddings = []\n",
    "#     for i in range(0, len(texts), batch_size):\n",
    "#         batch = texts[i:i+batch_size]\n",
    "#         embeddings.append(model.encode(batch, show_progress_bar=False))\n",
    "#         gc.collect()  # Force garbage collection\n",
    "#     return np.vstack(embeddings)\n",
    "\n",
    "# def main():\n",
    "#     # --- Load and preprocess data ---\n",
    "#     print(\"Loading data...\")\n",
    "#     try:\n",
    "#         df = pd.read_csv('./data/tmdb_rev.csv')\n",
    "#         df = df.dropna(subset=['overview', 'budget', 'release_year', 'revenue', 'title'])\n",
    "        \n",
    "#         # Sample data if too large (comment out for full dataset)\n",
    "#         df = df.sample(5000, random_state=42) if len(df) > 10000 else df\n",
    "        \n",
    "#         df['overview'] = df['overview'].fillna(\"\")\n",
    "#         df['budget'] = df['budget'].fillna(0).astype(np.float32)\n",
    "#         df['release_year'] = df['release_year'].fillna(0).astype(np.int16)\n",
    "#         df['revenue'] = df['revenue'].fillna(0).astype(np.float32)\n",
    "#     except Exception as e:\n",
    "#         print(f\"Data loading failed: {str(e)}\")\n",
    "#         return\n",
    "\n",
    "#     # --- Get overview embeddings in safe batches ---\n",
    "#     print(\"Generating embeddings...\")\n",
    "#     try:\n",
    "#         bert = SentenceTransformer('all-MiniLM-L6-v2')\n",
    "#         overview_embeddings = safe_embedding_generation(df['overview'].tolist(), bert, batch_size=50)\n",
    "        \n",
    "#         # Reduce dimensionality aggressively\n",
    "#         print(\"Reducing dimensions...\")\n",
    "#         pca = PCA(n_components=50)  # More aggressive reduction\n",
    "#         overview_embeddings = pca.fit_transform(overview_embeddings).astype(np.float32)\n",
    "#     except Exception as e:\n",
    "#         print(f\"Embedding generation failed: {str(e)}\")\n",
    "#         return\n",
    "\n",
    "#     # --- Features with memory optimization ---\n",
    "#     try:\n",
    "#         X = np.hstack([\n",
    "#             overview_embeddings,\n",
    "#             df[['budget', 'release_year']].values\n",
    "#         ]).astype(np.float32)\n",
    "#         y = np.log1p(df['revenue'].values).astype(np.float32)\n",
    "#         y = y.dropna()\n",
    "\n",
    "#         print(f\"Final data shape - X: {X.shape}, y: {y.shape}\")\n",
    "#         print(f\"Approximate memory usage: {X.nbytes / (1024**2):.2f} MB\")\n",
    "#     except Exception as e:\n",
    "#         print(f\"Feature preparation failed: {str(e)}\")\n",
    "#         return\n",
    "\n",
    "#     # --- Split & train with memory constraints ---\n",
    "#     print(\"Training model...\")\n",
    "#     try:\n",
    "#         X_train, X_test, y_train, y_test = train_test_split(\n",
    "#             X, y, test_size=0.2, random_state=42\n",
    "#         )\n",
    "        \n",
    "#         # Free memory\n",
    "#         del X, y, overview_embeddings, df\n",
    "#         gc.collect()\n",
    "\n",
    "#         model = LGBMRegressor(\n",
    "#             n_estimators=100,  # Reduced number\n",
    "#             random_state=42,\n",
    "#             max_depth=4,       # More shallow trees\n",
    "#             num_leaves=15,    # Fewer leaves\n",
    "#             subsample=0.7,    # Smaller fraction of data\n",
    "#             colsample_bytree=0.7,\n",
    "#             verbose=-1        # Silent training\n",
    "#         )\n",
    "        \n",
    "#         model.fit(X_train, y_train)\n",
    "        \n",
    "#         # --- Make predictions ---\n",
    "#         y_pred = model.predict(X_test)\n",
    "        \n",
    "#         # --- Evaluate the model ---\n",
    "#         mae = mean_absolute_error(np.expm1(y_test), np.expm1(y_pred))\n",
    "#         r2 = r2_score(y_test, y_pred)\n",
    "        \n",
    "#         print(f\"Mean Absolute Error (MAE): ${mae:,.2f}\")\n",
    "#         print(f\"R-squared (R²): {r2:.4f}\")\n",
    "#     except Exception as e:\n",
    "#         print(f\"Model training failed: {str(e)}\")\n",
    "#         return\n",
    "\n",
    "#     # --- Save the model and embeddings ---\n",
    "#     try:\n",
    "#         os.makedirs(\"models\", exist_ok=True)\n",
    "        \n",
    "#         # Save models with protocol=4 for better compatibility\n",
    "#         with open(\"models/revenue_model.pkl\", \"wb\") as f:\n",
    "#             pickle.dump(model, f, protocol=4)\n",
    "            \n",
    "#         with open(\"models/bert_model.pkl\", \"wb\") as f:\n",
    "#             pickle.dump(bert, f, protocol=4)\n",
    "            \n",
    "#         with open(\"models/pca_model.pkl\", \"wb\") as f:\n",
    "#             pickle.dump(pca, f, protocol=4)\n",
    "        \n",
    "#         # Save smaller reference data\n",
    "#         pd.DataFrame({\n",
    "#             'title': df['title'].iloc[:1000],  # Only save first 1000\n",
    "#             'overview': df['overview'].iloc[:1000]\n",
    "#         }).to_csv(\"models/title_reference.csv\", index=False)\n",
    "        \n",
    "#         # Save reduced embeddings\n",
    "#         np.save(\"models/overview_embeddings.npy\", overview_embeddings[:1000])  # Only first 1000\n",
    "        \n",
    "#         print(\"✅ Model training complete and saved.\")\n",
    "#     except Exception as e:\n",
    "#         print(f\"Model saving failed: {str(e)}\")\n",
    "\n",
    "# if __name__ == \"__main__\":\n",
    "#     main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: gensim in /Users/lasyayadlapati/miniforge3/envs/dsc80/lib/python3.12/site-packages (4.3.3)\n",
      "Requirement already satisfied: numpy<2.0,>=1.18.5 in /Users/lasyayadlapati/miniforge3/envs/dsc80/lib/python3.12/site-packages (from gensim) (1.26.4)\n",
      "Requirement already satisfied: scipy<1.14.0,>=1.7.0 in /Users/lasyayadlapati/miniforge3/envs/dsc80/lib/python3.12/site-packages (from gensim) (1.13.1)\n",
      "Requirement already satisfied: smart-open>=1.8.1 in /Users/lasyayadlapati/miniforge3/envs/dsc80/lib/python3.12/site-packages (from gensim) (7.1.0)\n",
      "Requirement already satisfied: wrapt in /Users/lasyayadlapati/miniforge3/envs/dsc80/lib/python3.12/site-packages (from smart-open>=1.8.1->gensim) (1.17.2)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: nltk in /Users/lasyayadlapati/miniforge3/envs/dsc80/lib/python3.12/site-packages (3.9.1)\n",
      "Requirement already satisfied: click in /Users/lasyayadlapati/miniforge3/envs/dsc80/lib/python3.12/site-packages (from nltk) (8.1.7)\n",
      "Requirement already satisfied: joblib in /Users/lasyayadlapati/miniforge3/envs/dsc80/lib/python3.12/site-packages (from nltk) (1.4.2)\n",
      "Requirement already satisfied: regex>=2021.8.3 in /Users/lasyayadlapati/miniforge3/envs/dsc80/lib/python3.12/site-packages (from nltk) (2024.11.6)\n",
      "Requirement already satisfied: tqdm in /Users/lasyayadlapati/miniforge3/envs/dsc80/lib/python3.12/site-packages (from nltk) (4.66.5)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: xgboost in /Users/lasyayadlapati/miniforge3/envs/dsc80/lib/python3.12/site-packages (2.1.4)\n",
      "Requirement already satisfied: numpy in /Users/lasyayadlapati/miniforge3/envs/dsc80/lib/python3.12/site-packages (from xgboost) (1.26.4)\n",
      "Requirement already satisfied: scipy in /Users/lasyayadlapati/miniforge3/envs/dsc80/lib/python3.12/site-packages (from xgboost) (1.13.1)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install gensim\n",
    "%pip install nltk\n",
    "%pip install xgboost\n",
    "%pip install cloudpickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package vader_lexicon to\n",
      "[nltk_data]     /Users/lasyayadlapati/nltk_data...\n",
      "[nltk_data]   Package vader_lexicon is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading GloVe embeddings...\n",
      "Training model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/lasyayadlapati/miniforge3/envs/dsc80/lib/python3.12/site-packages/xgboost/core.py:158: UserWarning: [19:10:56] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/Users/lasyayadlapati/miniforge3/envs/dsc80/lib/python3.12/site-packages/sklearn/pipeline.py:62: FutureWarning: This Pipeline instance is not fitted yet. Call 'fit' with appropriate arguments before using other methods such as transform, predict, etc. This will raise an error in 1.8 instead of the current warning.\n",
      "  warnings.warn(\n",
      "/Users/lasyayadlapati/miniforge3/envs/dsc80/lib/python3.12/site-packages/sklearn/preprocessing/_label.py:909: UserWarning: unknown class(es) ['100 Feet Productions', '1212 Entertainment', '2 Bridges Productions', '2 Loop Films', '23ten', '321 Films', '3Mark Entertainment', '3ality Digital Entertainment', '7 Bucks Entertainment', '88 Rising', 'A Loopy Production LLC', 'A Steven Haft Production', 'A.M.A. Film', 'A2 Entertainment Group', 'A7 EYES', 'ABS Production', 'AFPI', 'AH Films Entertainment', 'AR-TL', 'ASAF', 'ASAP Entertainment', 'Abraham Productions', 'Abramorama', 'Absolute Entertainment', 'Academy Pictures Corporation', 'Access Films', 'Actual Films', 'Adafine Entertainment', \"Aditya's group\", 'Adlabs Films Ltd.', 'Air Bud Entertainment', 'Albert Zugsmith Productions', 'Alberto Grimaldi Productions', 'Alf Halter Productions', 'All Knight Productions', 'All Pictures Media', 'Allied Stars', 'Also Known As Pictures', 'American Film Institute (AFI)', 'American Underground', 'American Werewolf Inc.', 'Anabasis N.V.', 'Andor Films', 'Andrea Leone Films', 'Anglo Enterprises', 'Anglo-Amalgamated', 'Animationsfabrik', 'Ankit Creations', 'Another Park Film', 'Anthony Hemingway Productions', 'Antron Media Production', 'Argos Films', 'Artimm', 'Artistic Films', 'Artistry Limited', 'Artists Releasing Corporation (ARC)', 'Ascot Elite Home Entertainment', 'Ashley Grenville and Soundfirm', 'Asis Productions', 'Astral Bellevue Pathé', 'Atchafalaya', 'Atlantic Records', 'Atomic Entertainment', 'Audiovisual e Multimédia', 'Autonomous', 'Avenging Conscience', 'Aversano Films', 'Azoff Entertainment', 'B22', 'B25 Entertainment', 'BCDF Pictures', 'BDE Entertainment', 'BFI Film Academy', 'BMC Productions', 'BOB Film Sweden', 'Babe Ruthless Productions', 'Bach Productions', 'Bad Cop / Bad Cop', 'Baird Film', 'Balochistan Academy', 'Baltimore Spring Creek Pictures', 'Bannon Films', 'Banter', 'Barwood Films', 'Baumgarten-Prophet Entertainment', 'Bay Point Media', 'Beachwold Productions', 'Beelz', 'Believe Entertainment', 'Bellatrix', 'Berg', 'Bergman Lustig Productions', 'Bert Marcus Film', 'Beryl Betty', 'Beyond Films', 'Big Brawl', 'Big Fan Productions', 'Blackout Productions Inc.', 'BlazeProductions', 'Bleeding Edge', 'Blood Iz Cool Productions', 'Blue Crow Productions', 'Blue Flower Productions', 'Blue Morning Pictures', 'Blue Parrot Productions', 'Blue Productions', 'Blue Sky Africa', 'Bob DeBrino Entertainment', 'Bobker / Kruger Films', 'Bogard', 'Boo Pictures', 'Bottom of the Ninth Productions', 'Boum Productions', 'Boy Culture LLC', 'Boy in the Box', 'Boy of the Year', 'Brad Zions Films', 'Brat Na Pont Productions', 'Braven NL', 'Braveworld Productions', 'Breaker', 'Brentwood Productions', 'Brezner', 'Brick Dust Productions LLC', 'Brick Mansions Productions', 'Broken Chair Flickz', 'Bron Capital Partners', 'Brooklyn Films II', 'Bruce Cohen Productions', 'Brynaprod S.A.', 'Bunim-Murray Productions (BMP)', 'Burek Films', 'Burr! Productions', 'Busted Shark Productions', \"Butcher's Run Productions\", 'Butimar Productions', 'Butterfield Producitons', 'C&P Productions', 'C.S. Lewis Company', 'C3 Entertainment', 'CAT Films', 'CBS Theatrical Films', 'CDI', 'CKRush Entertainment', 'CTV International', 'Caemhan', 'CalArts', 'Cambridge Productions', 'Camfam Studios', 'Camp Films', 'Canary Films (US)', 'Cantilever Media', 'Capella Films', 'Capri Releasing', 'Captain Movies', 'Carpe Diem Films', 'Case 39 Productions', 'Catalyst Global Media', 'Catwoman Films', 'Centropolis Film Productions', 'Chad Troutwine Films', 'Channel 83 Films', 'Chaotic Productions', 'Chargeurs', 'Cherokee Productions', 'Cherry Alley Productions', 'Chris Morgan Productions', 'Christmas Tree Films', 'Chu Studios', 'Cine-Clube de Avanca', 'Cinecom Entertainment Group', 'Cinema Plus', 'Cinema West Productions', 'Cinematronix', 'Cinevu Films', 'Cinépix Film Properties (CFP)', 'City Film Corporation', 'City on a Hill Productions', 'Clear Blue Sky Productions', 'Cliffbrook Films', 'Cliffhanger Productions', 'Clydeside Studios', 'Coatwolf Productions', 'Codi S.p.a.', 'Cohesive Entertainment Group', 'Colerful Spiderlegs', 'Collective Eye Films', 'Colorado Film School', 'Colour Line Productions', 'Colourframe', 'Columbus 81 Productions', 'Comedy Central', 'Cometstone Pictures', 'Compelling Pictures', 'Compound B', 'Conner Mac Studios', 'Constance Media', 'Cookout Productions', 'Cool Productions', 'Cor Cordium Productions', 'Corn Cobb Productions', 'Count of Monte Cristo Ltd.', 'Court Five', 'Courtside Seats Productions', 'Cowtown Cinema Ventures', 'Crazyscares production', \"Creative Skillset's Skills Investment Fund\", 'Creative Visions Productions', 'Creativity Capital', 'Crimson Bolt', 'Cristaldifilm', 'Crooked Highway', 'Crossroads Entertainment (II)', 'Crown International Pictures', 'Crucial Films', 'Crying Box Productions', 'Crystal Wealth', 'Cub Five Productions', 'Curiously Bright Entertainment', 'Curvy Studios', 'Czar Pictures', 'D&D Films', \"D'Artagnan Productions Limited\", 'DAL Productions', 'DMK Mediafonds International', 'DPI', 'DUST', 'DW Studios', 'Dadi Film Group', 'Dalton Films', 'Darius Films', 'Dark Harbor Stories', 'Dark Rain Entertainment', 'Dark Trick Films', 'Dawn Associates', 'Daybreak', 'Daydream Films', 'De Milo', 'De Negris Productions', 'Decade', 'Deep Films', 'Deeper Water', 'Delirio Films', 'Deon Taylor Enterprises', 'Desertlands Entertainment', 'Devon', 'Diamond Films', 'Digiart Productions', 'Digital Domain', 'Digital Idea', 'Dinamo Entertainment', 'Distant Planet Productions', 'Dogfish Pictures', 'Dolly Hall Productions', 'Doom Productions', 'Douglas', 'Douglas & Lewis Productions', 'Dr D Studios', 'Dragon Pictures', 'Duck Diver Films', 'D²', 'E.K.', 'EDI', 'Earth Canada Productions', 'Earth Girls', 'Earthship Productions', 'Eaves Movie Ranch', 'Eclectic pictures', 'Eclipse Films', 'Eclipse Pictures', 'Eden Wurmfeld Films', 'Edmonds Entertainment Group', 'Een and Ourt Productions Limited', 'Eggplant Picture & Sound', 'Eketahuna LLC', 'El Norte Productions', 'Elara Pictures', 'Elcajo Productions', 'Electric Dynamite', 'Electronic Arts', 'Elfte Babelsberg Film GmbH', 'Embassy Pictures Corporation', 'Emergence Entertainment', 'Enchanted Productions', 'Enchanter Entertainment', 'Enlightened Kingdom', 'Entertainment Events', 'Epidemic Pictures', 'Essential Media and Entertainment', 'Essex Productions', 'Estudios Churubusco Azteca', 'Eulogy Productions LLC', 'Euphoria Media Inc.', 'European Motion Pictures Productions Ltd', 'Exclusive Films', 'Exodus Film Group', 'Exodus Productions', 'Extra A Productions', 'Eye On The Ball Films', 'F & F VI Productions A.I.E', 'FIDECINE', 'Fabula Pictures', 'Failure to Launch Productions', \"Falcon's Flight\", 'Fallingcloud', 'Famous Artists Productions', 'Famous Films', 'Fanfare Films', 'Fangoria Films', 'Far Cry Productions', 'Feast of Fools Productions', 'Fellowship Adventure Group', 'Fiddly Fig Animation Studios', 'Fig Production Group', 'Film Brigade', 'Film Consortium', 'Film Forge Productions', 'Film Gallery', 'Film Guild Productions', 'Film Ventures International', 'Film Visions Funding', 'Filmförderung Hamburg Schleswig-Holstein', 'Filmsmith Productions', 'Finding Forrester Productions', 'Firefly Films', 'Fireworks Entertainment', 'First Cinema Pictures', 'First Knight Productions', 'First Point Entertainment', 'FlipZide', 'Flypaper Press', 'Focusfilm Kft.', 'Footprint Investment Fund', 'Foqus Arte Digital', 'Forthcoming Films', 'Foundry Films', 'Four-Leaf Productions', 'Fox Films Ltd.', 'Fox Television Studios', 'FoxTrot Productions', 'Frame 48', 'Framestore', 'France 3', 'Frantic Films', 'Freerunning', 'Fremantle Productions', 'Fria Luz Del Dia', 'Full Sail University', 'G.D Stami', 'G.P.L.A.', 'GRPW The Heart Of Gold', 'Galante Movie Productions', 'Galatée Films', 'Gecko Films', 'George Sidney Productions', 'George Street Pictures', 'Gil Friesen Productions', 'Gila Film', 'Gimme Five Films', 'Giving Films', 'Global Cinema Group', 'Globetrotter Productions', 'Goatworks Films', 'Golar Productions', 'Good Wizard', 'Googly Films', 'Gordon Bijelonic / Datari Turner Films', 'Grand Illusions Entertainment', 'Grand Slam Productions', 'Gray Daisy Films', 'Green Film Company', 'Green Moon Productions', 'Greenfox', 'Greenway Productions', 'Greg Jenkins Productions', 'Gremi Film Production', 'Groucho II Film Partnership', 'Groucho III Film Partnership', 'Ground Control Entertainment', 'H2S2 Filmproduktionsgesellschaft', 'Halt Productions', 'Hannah Rachel Production Services', 'Harbinger Pictures', 'Harbour Pictures', 'Harlequin Pictures', 'Harwood Hunt Productions', 'Hassell Free Production', 'Haven Entertainment', 'Headshot Films', 'Hear/Say Productions', 'Hecht-Lancaster Productions', 'Helen Productions', 'Henro Media', 'Henry Art Gallery', 'Hera Productions', 'Herbert M. Dawley Production', 'Hero Entertainment', 'Hero Squared', 'Hideout Films', 'Hideout Pictures', 'Highlander Productions Limited', 'Highwayman Films', 'Hit & Run Productions', 'Hollydan Works', 'Hollywood Storm', 'Hombre Productions', 'Homerun Productions', 'House Row Productions', 'Howard Hughes Productions', 'Human Worldwide', 'Hurwitz & Schlossberg Productions', 'Hyperobject Industries', 'IDG China Media', 'IN MEMORY OF MR. DEZIO', 'IRS Media', 'IamOTHER Entertainment', 'Ignition Film Productions', 'Imagination Design Works', 'Imagine Rights', 'Immortal Entertainment', 'Independent', 'Independent Lens', 'Indie Entertainment', 'Indion Entertainment Group', 'Indy Film House', 'Inferno Entertainment', 'Initial Films', 'Initial Groupe', 'Initial Pictures', 'Innovisions', 'Insight Film Releasing', 'Instituto Mexicano de Cinematografía', 'Instituto do Cinema', 'Intandem Films', 'Intercut Capital', 'Interior13 Cine', 'Internationale Filmproduktion Stella-del-Sud Second', 'Investors In Industry PLC', 'Invico Capital', 'Island Films', 'Itasca Pictures', 'J&M Entertainment', 'J.K. Livin Productions', 'JD Productions', 'JDI productions', 'Jackie O Productions', 'Jaibol Films', 'Janky Jank Productions', 'Jason Productions', 'Jay Book Movies', 'Jeff Brothers Productions', 'Jewell Enterprises Inc.', 'Joel Productions', 'John Boorman Productions', 'John Frankenheimer Productions Inc.', 'Joi Productions', 'Jolie Pas', 'Jose and Friends Inc.', 'Jugman Productions', 'Julia Phillips and Michael Phillips Productions', 'Jurow-Shepherd', 'KRU Studios', 'Kanaki Films', 'Kappa', 'Kava Productions', 'Kawoosh! Productions DTV I', 'Kech', 'Kestrel Films', 'Kettledrum Films', 'Ki11er Productions', 'Kindred Spirit', 'King of California Productions', 'Kinodanz', 'Kinoklub Zagreb', 'Kinétique Inc.', 'Koan Films', 'Kong Gulerod Film', 'Kouf/Bigelow Productions', 'Kumar Mobiliengesellschaft mbH & Co. Projekt Nr. 3 KG', 'L.A. Films', 'LBN TV NETWORKS', 'LDMP', 'LQ/JAF', 'La Belle Allee Productions', 'La Compagnie Cinématographique', 'LaVoo Productions', 'Ladbroke', 'Lagniappe Films', 'Lago Films', 'Lamp Entertainment BD', 'Langley Films', 'Langley Productions', 'Las Producciones del Escorpion', 'Lascaux Films', 'Lasser Productions', 'Latitude Productions', 'Laurinfilm', 'Le Bureau', 'Le Vision Pictures', 'Leaves Productions', 'Legendary East', 'Lemon Sky Productions', 'Leo McWatkins', 'Leone Film Group', 'Les Films 21', 'Les Productions Bagheera', 'Liberty Pictures', 'Liberty University', 'Light and Dark Films', 'Lime Orchard Productions', 'Limelight Fund', 'Lisberger/Kushner Productions', 'Little Gaddesden Productions', 'Little Ugly', 'Living the Dream Films', 'Loki Films', 'Londinium Films', 'Lone Star Film Group', 'Los Angeles', 'Lotus Production', 'Lovely Productions', 'Ltd.', 'Lucille Ball Productions', 'Lucky 50 Productions', 'Luna Filmproduktion', 'Lunar Industries', 'Lydiard Films', 'Lyncanthrope Films', 'M & A', 'M.G. Films', 'MBC Beteiligungs Filmproduktion', 'MDP Filmproduktion', 'ME2 Productions', 'MGM-Pathé Communications', 'MGee Films', 'Mabel Normand Feature Film Company', 'MacGowan Films', 'Mad Dog Productions', 'Magna Group Entertainment', 'Mai Juin Productions', 'Maipo Film', 'Malavita', 'Malvern Pictures', 'Mambo Ya Town Huezi Elewa', 'Maple Shade Films', 'Maraci/Edelstein Films', 'Marble Arch Productions', 'Marcy Media', 'Marimark Productions', 'Mark Banks Entertainment', 'Marro Films', 'Marvel Knights', 'Matchmaker Films', 'Mattel', 'Max Stronghold Productions Inc.', 'McLaughlin Films', 'Mecklenburg Vorpommern', 'Media Finance Capital', 'Media Home Entertainment', 'Mediaworks', 'Medici Entertainment', 'Melbarken', 'Melodrama Pictures', 'Melvin Simon Productions', 'Mercury', 'Mercury Productions', 'Meridian Productions', 'Metanoia Films', 'Meteor Joint Venture', 'Metro-Goldwyn Pictures Corporation', 'Metropolis Films', 'Michael Alden Productions', 'Michael Edgley International', 'Michael Lobell Productions', 'Michael Powell (Theatre)', 'Michael Todd Company', 'Mighty Mighty Afrodite Productions', 'Milk & Media', 'Milkshake Films', 'Millimeter Films', 'Mimosa Films', 'Mind the GAP Productions', 'MindSky Entertainment', 'Mindfire Entertainment', 'Mirage Films', 'Mirror Films', 'Misha Films', 'Mission Pictures International', 'Mississippix Studios', 'Mobius Entertainment Ltd.', 'Modern People', 'Moguletta', 'Molen/Garbett Productions', 'Mondo Macabro', 'Monkey Dance Productions', 'Monolith Films', 'Morales Foto y Video.', 'Morra', 'Motion Investment Group', 'Motion Picture ETA Produktionsgesellschaft', 'Moviefan Scandinavia A/S', 'Muse of Fire', 'Mutant Enemy Productions', 'Mutiny Motion Pictures', 'Mystery Forest', 'Möbius Entertainment', 'NT2 Productions', 'NWR Film Productions', 'Nanny McPhee Productions', 'Napoleon Pictures Limited', 'Narrative Capital', 'Narrativia', 'Natant', 'Nateflix Productions', 'National Geographic', 'Native Pictures Productions', 'Necropia Entertainment', 'Neon', 'Net Entertainment', 'New Amsterdam Entertainment', 'New Deal Studios', 'New Element Media', 'New Horizons Picture', 'New Star Entertainment', 'New Zealand Motor Corporation', 'New Zealand Railways', 'New Zealand United', 'Niche Film Sdn Bhd', 'Nichol Moon Films', 'Nicita/Lloyd Productions', 'Nine Yards Two Productions', 'Nokkvi', 'Northwood Productions', 'Nota Bene Film Group', 'Nu Boyana Viburno', 'Nube Tube Filming', 'Nvizage', 'O. Hannah Films', 'O.N.C. Entertainment', 'ODB Films', 'OMOCAT', 'OZ Academy', 'Ocelot Films Inc.', 'Oculus Productions', 'Off World Films', 'Ohio State University', 'Okko Production', 'Omni Zoetrope Studios', 'On the Road', 'One America', 'One Eye Production', 'Oneder Studios', 'Onset Films', 'Open City Films', 'Orange Corp', 'Orchard Productions', 'Origin Pictures', 'Oscar Generale Productions', 'Otis Productions', 'Out of Africa Entertainment', 'Outside Da Box', 'Ovation Entertainment', 'Ozumi Films', 'P & L', 'P&C Arcade Film Fund', 'P2 Films', 'PT Budiana Film', 'Pakula-Mulligan', 'Palladium', 'Panaramic', 'Pandora Pictures', 'Paperback Muse Productions', 'Paragon Arts International', 'Parallel Media', 'Parker-Stone Productions', 'Part II Productions', 'Particular Crowd', 'Patalex V Productions Limited', 'Paul Allen Films', 'Paul Schrader Productions', 'Peach Trees', 'Peak Productions', 'Pearl River Film Studio', 'Pellikola Limited', 'Perfect Inframe', 'Perfect Weekend', 'Periscope Entertainment', 'Perry Players', 'Peter Frankfurt Productions', 'Picture Machine', 'Picture Palace North', 'Pierce-Williams', 'Pigeon Creek Films', 'PingPongFilm', 'Pink Machine', 'Pioneer', 'Planman Motion Pictures', 'Platige Films', 'Playboy Enterprises', 'Playwrights Horizons', 'Plunge Pictures LLC', 'Plural Entertainment', 'Point Blank Productions', 'Polar Productions', 'Police Academy Productions', 'Pork Pie Productions', 'Portman Entertainment Group', 'Portman Productions', 'Possessed Pictures', 'Powderkeg Pictures', 'Pretzel Fang Productions', 'Price Productions', 'Pride of Gypsies', 'Primary Productions', 'Primary Wave Entertainment', 'Primetime Pictures', 'Principal Films', 'Pro-Wrestling: EVE', 'Pro-ject Filmproduktion', 'Prodigy Pictures', 'Promises Entertainment', 'Propeler', 'Prosperity Pictures', 'Prototype', 'Pub Quiz Productions', 'Pulling Focus Pictures', 'Puppetworks Animation Studio', 'Pure Grass Films', 'Pyromid Pictures', 'Q&Q Medien GmbH', 'Quality Growth International Ltd.', 'Quantum Films', 'Queen Films', 'Questar Entertainment', 'Quincy Jones-David Salzman Entertainment', 'R.A. Productions', 'R.G. Studio', 'R.P. Films', 'RAI Cinema', 'RTBF', 'Raees Jeelani', 'Rainmark Films', 'Rampage Entertainment', 'Reaper Productions', 'Red And Black Films', 'Red Bull Media House', 'Red Dog Films', 'Red Envelope Entertainment', 'Red Light Films', 'Red Sun Productions Pty. Ltd.', 'Red Tower Films', 'Red-Horse Native Productions', 'Redford-Ritchie Productions', 'Redrum Films', 'Rena Film', 'Renegade Productions', 'Renegade Worldwide', 'Representational Pictures', 'Republic Pictures (II)', 'Retham Production', 'Reverb Nation', 'Revere Pictures', 'Rich Pickings', 'Richard Pryor Productions', 'Richmond Productions', 'Riff Raff Film Productions', 'Rimfire Films', 'Rip Cord Productions', 'Robert Fleming Leasing Limited', 'Rockbuster Productions', 'Rockinghorse Films', 'Roger Avary Filmproduktion GmbH', 'Rogue Star Productions', 'Rolling Hills', 'Rose Pictures', 'Roy Export Company Establishment', 'Royal Cupcake Productions', 'Rumble Riot Pictures', 'Runaway Fridge Productions', 'Rutgers University Film Productions', 'Rye Road Productions', 'S Films', 'S.O.A.F. Productions', 'SAF Productions', 'SB Projects', 'SGF Entertainment', 'SODEC', 'SPD Films', 'SPI Film Studio', 'SWFX', 'Sage Stone Productions', 'Sagittaire Films', 'Salem Street Entertainment', 'San Francisco Independent Cinema', 'Saratoga Entertainment', 'SarcoFilms', 'Saul Zaentz Film Productions', 'Savalas Audio Post-Production', 'Scarecrow Productions', 'Scared Productions', 'Scorpio East Pictures', 'Scotlawood Motion Pictures', 'Screen East', 'See Film', 'Seesaw Productions', 'Selima Films AVV', 'Selmur Productions', 'Seltser Studios JR', 'Senator Entertainment', 'Seneca Falls Picture Company', 'Senorita Films', 'Seraph Films', 'Seraphim Films', 'Serena Films', 'Serenade Films', 'Serio Controla Entertainment', 'Serio Controla Records', 'ShadowCatcher Entertainment', 'Shamley Productions', 'Shanghai RuYi Entertainment', 'Shelter Prod', 'Shep Films', 'Shifting Gears Entertainment', 'Shomedia', 'Short Porch Pictures', 'Shut Up & Shoot Pictures', 'Shutt/Jones Productions', 'Silverbell Films', 'Simkoe', 'Sixty-Six Production', 'Skellington Productions Inc.', 'Sky Pictures', 'Sky Studios', 'Sleigher Studios', 'Slime23Films', 'Small World Entertainment', 'Smash Wrestling (Smash)', 'Smoking Gun Productions', 'Snack Crackers Productions', 'Snowy River Investment Pty. Ltd.', 'Sociedad General de Cine S.A.', 'Sogecine', 'Soli Deo Gloria Releasing', 'Solomon/Hackett Productions', 'Source Management + Production', 'South Australian Feature Film Company', 'South Park Studios', 'Southern Comedy Theatre Company', 'Spacemaker Productions', 'Sparkle Roll Media', 'Sparkler Entertainment', 'Sparx Animation Studios', 'Sphere Films', 'Spinning Gasing Films Sdn Bhd', 'Sprockefeller Pictures', 'Sprockets Music', 'Squeeze', 'St. Michael Finance Limited', 'Stan', 'Stan Winston Productions', 'Star Overseas', 'Stardust International', 'Starlight Culture Entertainment Group', 'Starmotion Pictures', 'Stay Gold Features', 'Steel Pictures', 'Steelwork Films', 'Steinberg and Tenenbaum Entertainment (MBST)', 'Stellarblade', 'Steven Clarke Productions', 'Stoller Global Solutions', 'Stone Canyon Entertainment', 'Streamline Global', 'Studio Deen', 'Studio Hamburg WorldWide Pictures', 'Studio Rakete', 'Studio Reborn', 'Subotica', 'Subterranean Productions LLC', 'Subterranean Productions UK Ltd.', 'Summerstorm Entertainment', 'Sundance Institute', 'Sunday Productions', 'Sunrise Filmvertriebs', 'Sunset Gower Studios', 'Suresh Productions', 'Surreel', 'Sweet Tea Pictures LLC', 'TCYK North Productions', 'Take no1', 'Taleswapper', 'TaliaFilm II Productions', 'Tang Media Productions', 'Tarzana Productions', 'Team Ninja', 'Tecmo', 'Televisa', 'Templar Films', 'Templeton Media', 'Tempête Sous Un Crâne Productions', 'Ten Thirteen Productions', 'Tequila Gang', 'Terence Michael Productions', 'Texas Chainsaw Productions', 'The 7th Floor', 'The Alamo Company', 'The Archives Project', 'The Caddo Company', 'The Elm Street Venture', 'The Entertainer Production Company', 'The Imaginarium', 'The Irwin Yablans Company', 'The Jozak Company', 'The Lloyd Segan Company', 'The Mirage Movies', 'The Vault', 'The Walk', 'The Weather Man', 'The Works International', 'The Wyland Group', 'Thomasville Pictures', 'Thomson Productions', 'Three Wolves Productions', 'Tiger Moth Productions', 'Tiger Tail Entertainment', 'Tijuana Productions', 'Timberlane Productions', 'Time Productions', 'TimeLine Films', 'Tin Toy Productions LLC', 'Tinker Productions', 'Tiver Studios', 'Toma 78', 'Tonik Productions', 'Top Shelf Productions', 'Tracy Films', 'Trailblazer Films', 'Trans-Film', 'Traveling Picture Show Company (TPSC)', 'Treasure Entertainment', 'Tree Top Films Inc.', 'TreeHouse Productions', 'Tremolo Productions', 'Triangle Film Corporation', 'Tribus P Film', 'True Grit Productions', 'Turbat', 'Turbo Productions', 'Twister Productions', 'Two Rivers Baptist Church', 'Tycho Tron Productions', 'Umbrella-Rosenblum Film Production', 'UnLTD Productions', 'Unanimous Entertainment', 'Uncharted', 'Underwater Productions', 'Underworld Produktions GmbH', 'Unfaithful Filmproduktion GmbH & Co. KG', 'Union Générale Cinématographique', 'Universal Animation Studios', 'Universal Pictures Home Entertainment', 'Unstoppable Film and Television', 'VAE Productions', 'VIP 3 Medienfonds', 'VN Productions', 'Valentina Films', 'Valentine Street Productions', 'Varient Busted Buggy Entertainmen', 'Vast Entertainment', 'Vedette Finance', 'Vegas Productions', 'Velvet Film', 'Venus Castina Productions', 'Versus Entertainment', 'Vincent Gallo Films', 'Vineyard Film', 'Vision Video Gateway Films', 'Vortex', 'Vortex/Henkel/Hooper', 'W-film', 'WTS Film', 'WV Films LLC', 'WWE Home Video', 'Walking Earth Media', 'Walking The Dog', 'Wallis-Hazen Inc.', 'Walt Disney Studios Home Entertainment', 'Wanda Media Co.', 'Wandering Star Pictures', 'Wark Producing Corp.', 'Warner Bros.', 'Warren Tech', 'Waterfall Media', 'Wave Pictures', 'Weird Life Films', 'Weldon Pictures Corp.', 'Wes Craven Films', 'Wessler Entertainment', 'West Madison Entertainment', 'Weston Woods Studios', 'Whamaphram Productions', 'White Rabbit Productions', 'Whitest Pouring Films', 'Wicker Man Productions', 'Wild Things Productions', 'William Dozier Productions', 'Witness Protection Films', 'Woodcote', 'World Film Magic', 'World Film Services', 'Wrather Productions', 'WrestleCade Entertainment', 'Wüste Film', 'Xingu Films', 'Yari Film Group Releasing', 'Yellowbird Productions', 'Yukon Film Incentive Program', 'ZEE5', 'Zaamur Production', 'Zanagar Films', 'Zazie Productions', 'cyntwix', 'icon', 'junifromspykids', 'ladyqueerfoot inc', 'truTV'] will be ignored\n",
      "  warnings.warn(\n",
      "/Users/lasyayadlapati/miniforge3/envs/dsc80/lib/python3.12/site-packages/sklearn/preprocessing/_label.py:909: UserWarning: unknown class(es) ['Botswana', 'Liechtenstein', 'Paraguay', 'Uruguay'] will be ignored\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Accuracy: 0.6569506726457399\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        Flop       0.78      0.87      0.82       823\n",
      "     Average       0.46      0.55      0.50       440\n",
      "         Hit       0.22      0.03      0.05       190\n",
      " Blockbuster       0.65      0.63      0.64       331\n",
      "\n",
      "    accuracy                           0.66      1784\n",
      "   macro avg       0.53      0.52      0.50      1784\n",
      "weighted avg       0.62      0.66      0.63      1784\n",
      "\n",
      "✅ Model saved using cloudpickle at models/final_model.pkl\n"
     ]
    }
   ],
   "source": [
    "# Improved Classification Pipeline Using GloVe Embeddings + Tuned XGBoost + Enhanced Features\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import ast\n",
    "import gensim.downloader as api\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from nltk.sentiment import SentimentIntensityAnalyzer\n",
    "import nltk\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "df = pd.read_csv('./data/tmdb_rev.csv')\n",
    "df = df[df[\"budget\"] != 0]\n",
    "# removing the genres that are not strings\n",
    "df = df[df['genres'].apply(lambda x: isinstance(x, str))]\n",
    "\n",
    "# Step 1: Convert genre strings into lists\n",
    "list_genres = df[\"genres\"].dropna().apply(lambda x: [g.strip() for g in x.split(\",\")])\n",
    "\n",
    "# Step 2: Flatten and collect unique genres\n",
    "unique_genres = set(genre for sublist in list_genres for genre in sublist)\n",
    "\n",
    "# Optional: Sort alphabetically\n",
    "unique_genres = sorted(unique_genres)\n",
    "\n",
    "selected_genres = ['Action', 'Adventure', 'Comedy', 'Crime', 'Drama', 'Fantasy', 'Romance', 'Science Fiction', 'Thriller']\n",
    "\n",
    "# Parse genres to list\n",
    "df['genre_list'] = df['genres'].apply(lambda x: [g.strip() for g in x.split(',') if g.strip() in selected_genres])\n",
    "\n",
    "\n",
    "nltk.download('vader_lexicon')\n",
    "\n",
    "# ---------- Load GloVe ----------\n",
    "print(\"Loading GloVe embeddings...\")\n",
    "glove_model = api.load(\"glove-wiki-gigaword-100\")\n",
    "\n",
    "# ---------- Custom Transformers ----------\n",
    "class ListToWordsTransformer(BaseEstimator, TransformerMixin):\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "    def transform(self, X):\n",
    "        return X.apply(lambda x: ast.literal_eval(x) if isinstance(x, str) else x)\n",
    "\n",
    "class TextToWordList(BaseEstimator, TransformerMixin):\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "    def transform(self, X):\n",
    "        return X.fillna(\"\").apply(lambda x: x.lower().split())\n",
    "\n",
    "class PretrainedEmbeddingTransformer(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, model, vector_size):\n",
    "        self.model = model\n",
    "        self.vector_size = vector_size\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        result = []\n",
    "        for item in X:\n",
    "            vectors = [self.model[word] for word in item if word in self.model]\n",
    "            avg_vector = np.mean(vectors, axis=0) if vectors else np.zeros(self.vector_size)\n",
    "            result.append(avg_vector)\n",
    "        return np.array(result)\n",
    "\n",
    "class SentimentExtractor(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self):\n",
    "        self.analyzer = SentimentIntensityAnalyzer()\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        return X.fillna(\"\").apply(lambda x: self.analyzer.polarity_scores(x)['compound']).to_frame()\n",
    "\n",
    "# ---------- Data Preparation ----------\n",
    "\n",
    "# Bin revenue into categories (e.g., flop, average, hit, blockbuster)\n",
    "revenue_bins = [0, 1e7, 5e7, 1e8, np.inf]\n",
    "bin_labels = [0, 1, 2, 3]\n",
    "df['revenue_class'] = pd.cut(df['revenue'], bins=revenue_bins, labels=bin_labels)\n",
    "df = df.dropna(subset=['revenue_class'])\n",
    "y = df['revenue_class'].astype(int)\n",
    "\n",
    "# Features\n",
    "X = df[['runtime', 'adult', 'budget', 'overview', 'genre_list', 'production_companies', 'production_countries']]\n",
    "\n",
    "# ---------- Train/Test Split ----------\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
    "\n",
    "# ---------- GloVe & Sentiment Pipelines ----------\n",
    "overview_glove = Pipeline([\n",
    "    ('text_to_words', TextToWordList()),\n",
    "    ('glove_embed', PretrainedEmbeddingTransformer(glove_model, 100))\n",
    "])\n",
    "\n",
    "genre_glove = Pipeline([\n",
    "    ('list_to_words', ListToWordsTransformer()),\n",
    "    ('glove_embed', PretrainedEmbeddingTransformer(glove_model, 100))\n",
    "])\n",
    "\n",
    "sentiment_pipe = Pipeline([\n",
    "    ('sentiment', SentimentExtractor())\n",
    "])\n",
    "\n",
    "# ---------- Multi-hot Pipelines for company/country ----------\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "\n",
    "class MultiLabelBinarizerTransformer(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self):\n",
    "        self.mlb = MultiLabelBinarizer()\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        parsed = X.apply(self._safe_parse)\n",
    "        self.mlb.fit(parsed)\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        parsed = X.apply(self._safe_parse)\n",
    "        return self.mlb.transform(parsed)\n",
    "\n",
    "    def _safe_parse(self, x):\n",
    "        if isinstance(x, list):\n",
    "            return x\n",
    "        if isinstance(x, str):\n",
    "            try:\n",
    "                return ast.literal_eval(x)\n",
    "            except (ValueError, SyntaxError):\n",
    "                return [item.strip() for item in x.split(\",\") if item.strip()]\n",
    "        return []\n",
    "\n",
    "company_pipe = Pipeline([\n",
    "    ('mlb', MultiLabelBinarizerTransformer())\n",
    "])\n",
    "\n",
    "country_pipe = Pipeline([\n",
    "    ('mlb', MultiLabelBinarizerTransformer())\n",
    "])\n",
    "\n",
    "# ---------- Preprocessing ColumnTransformer ----------\n",
    "preprocessor = ColumnTransformer(transformers=[\n",
    "    ('runtime', StandardScaler(), ['runtime']),\n",
    "    ('budget', StandardScaler(), ['budget']),\n",
    "    ('adult', OneHotEncoder(drop='if_binary'), ['adult']),\n",
    "    ('overview_glove', overview_glove, 'overview'),\n",
    "    ('genre_glove', genre_glove, 'genre_list'),\n",
    "    ('companies', company_pipe, 'production_companies'),\n",
    "    ('countries', country_pipe, 'production_countries'),\n",
    "    ('sentiment', sentiment_pipe, 'overview')\n",
    "])\n",
    "\n",
    "# ---------- Full Model Pipeline ----------\n",
    "model = Pipeline([\n",
    "    ('preprocessing', preprocessor),\n",
    "    ('classifier', XGBClassifier(\n",
    "        n_estimators=300,\n",
    "        max_depth=8,\n",
    "        learning_rate=0.05,\n",
    "        subsample=0.85,\n",
    "        colsample_bytree=0.85,\n",
    "        use_label_encoder=False,\n",
    "        eval_metric='mlogloss',\n",
    "        random_state=42\n",
    "    ))\n",
    "])\n",
    "\n",
    "# ---------- Train & Evaluate ----------\n",
    "print(\"Training model...\")\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "print(\"\\nAccuracy:\", accuracy_score(y_test, y_pred))\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_test, y_pred, target_names=['Flop', 'Average', 'Hit', 'Blockbuster']))\n",
    "\n",
    "import cloudpickle\n",
    "import os\n",
    "\n",
    "os.makedirs(\"models\", exist_ok=True)\n",
    "\n",
    "with open(\"models/final_model.pkl\", \"wb\") as f:\n",
    "    cloudpickle.dump(model, f)\n",
    "\n",
    "print(\"✅ Model saved using cloudpickle at models/final_model.pkl\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: sentence_transformers in /Users/lasyayadlapati/miniforge3/envs/dsc80/lib/python3.12/site-packages (4.0.2)\n",
      "Requirement already satisfied: transformers<5.0.0,>=4.41.0 in /Users/lasyayadlapati/miniforge3/envs/dsc80/lib/python3.12/site-packages (from sentence_transformers) (4.51.1)\n",
      "Requirement already satisfied: tqdm in /Users/lasyayadlapati/miniforge3/envs/dsc80/lib/python3.12/site-packages (from sentence_transformers) (4.66.5)\n",
      "Requirement already satisfied: torch>=1.11.0 in /Users/lasyayadlapati/miniforge3/envs/dsc80/lib/python3.12/site-packages (from sentence_transformers) (2.6.0)\n",
      "Requirement already satisfied: scikit-learn in /Users/lasyayadlapati/miniforge3/envs/dsc80/lib/python3.12/site-packages (from sentence_transformers) (1.6.1)\n",
      "Requirement already satisfied: scipy in /Users/lasyayadlapati/miniforge3/envs/dsc80/lib/python3.12/site-packages (from sentence_transformers) (1.13.1)\n",
      "Requirement already satisfied: huggingface-hub>=0.20.0 in /Users/lasyayadlapati/miniforge3/envs/dsc80/lib/python3.12/site-packages (from sentence_transformers) (0.30.1)\n",
      "Requirement already satisfied: Pillow in /Users/lasyayadlapati/miniforge3/envs/dsc80/lib/python3.12/site-packages (from sentence_transformers) (10.4.0)\n",
      "Requirement already satisfied: typing_extensions>=4.5.0 in /Users/lasyayadlapati/miniforge3/envs/dsc80/lib/python3.12/site-packages (from sentence_transformers) (4.12.2)\n",
      "Requirement already satisfied: filelock in /Users/lasyayadlapati/miniforge3/envs/dsc80/lib/python3.12/site-packages (from huggingface-hub>=0.20.0->sentence_transformers) (3.18.0)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /Users/lasyayadlapati/miniforge3/envs/dsc80/lib/python3.12/site-packages (from huggingface-hub>=0.20.0->sentence_transformers) (2025.3.2)\n",
      "Requirement already satisfied: packaging>=20.9 in /Users/lasyayadlapati/miniforge3/envs/dsc80/lib/python3.12/site-packages (from huggingface-hub>=0.20.0->sentence_transformers) (24.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /Users/lasyayadlapati/miniforge3/envs/dsc80/lib/python3.12/site-packages (from huggingface-hub>=0.20.0->sentence_transformers) (6.0.2)\n",
      "Requirement already satisfied: requests in /Users/lasyayadlapati/miniforge3/envs/dsc80/lib/python3.12/site-packages (from huggingface-hub>=0.20.0->sentence_transformers) (2.32.3)\n",
      "Requirement already satisfied: networkx in /Users/lasyayadlapati/miniforge3/envs/dsc80/lib/python3.12/site-packages (from torch>=1.11.0->sentence_transformers) (3.3)\n",
      "Requirement already satisfied: jinja2 in /Users/lasyayadlapati/miniforge3/envs/dsc80/lib/python3.12/site-packages (from torch>=1.11.0->sentence_transformers) (3.1.4)\n",
      "Requirement already satisfied: setuptools in /Users/lasyayadlapati/miniforge3/envs/dsc80/lib/python3.12/site-packages (from torch>=1.11.0->sentence_transformers) (75.1.0)\n",
      "Requirement already satisfied: sympy==1.13.1 in /Users/lasyayadlapati/miniforge3/envs/dsc80/lib/python3.12/site-packages (from torch>=1.11.0->sentence_transformers) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /Users/lasyayadlapati/miniforge3/envs/dsc80/lib/python3.12/site-packages (from sympy==1.13.1->torch>=1.11.0->sentence_transformers) (1.3.0)\n",
      "Requirement already satisfied: numpy>=1.17 in /Users/lasyayadlapati/miniforge3/envs/dsc80/lib/python3.12/site-packages (from transformers<5.0.0,>=4.41.0->sentence_transformers) (1.26.4)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /Users/lasyayadlapati/miniforge3/envs/dsc80/lib/python3.12/site-packages (from transformers<5.0.0,>=4.41.0->sentence_transformers) (2024.11.6)\n",
      "Requirement already satisfied: tokenizers<0.22,>=0.21 in /Users/lasyayadlapati/miniforge3/envs/dsc80/lib/python3.12/site-packages (from transformers<5.0.0,>=4.41.0->sentence_transformers) (0.21.1)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in /Users/lasyayadlapati/miniforge3/envs/dsc80/lib/python3.12/site-packages (from transformers<5.0.0,>=4.41.0->sentence_transformers) (0.5.3)\n",
      "Requirement already satisfied: joblib>=1.2.0 in /Users/lasyayadlapati/miniforge3/envs/dsc80/lib/python3.12/site-packages (from scikit-learn->sentence_transformers) (1.4.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in /Users/lasyayadlapati/miniforge3/envs/dsc80/lib/python3.12/site-packages (from scikit-learn->sentence_transformers) (3.5.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /Users/lasyayadlapati/miniforge3/envs/dsc80/lib/python3.12/site-packages (from jinja2->torch>=1.11.0->sentence_transformers) (2.1.5)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/lasyayadlapati/miniforge3/envs/dsc80/lib/python3.12/site-packages (from requests->huggingface-hub>=0.20.0->sentence_transformers) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/lasyayadlapati/miniforge3/envs/dsc80/lib/python3.12/site-packages (from requests->huggingface-hub>=0.20.0->sentence_transformers) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/lasyayadlapati/miniforge3/envs/dsc80/lib/python3.12/site-packages (from requests->huggingface-hub>=0.20.0->sentence_transformers) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/lasyayadlapati/miniforge3/envs/dsc80/lib/python3.12/site-packages (from requests->huggingface-hub>=0.20.0->sentence_transformers) (2024.8.30)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: transformers in /Users/lasyayadlapati/miniforge3/envs/dsc80/lib/python3.12/site-packages (4.51.1)\n",
      "Requirement already satisfied: filelock in /Users/lasyayadlapati/miniforge3/envs/dsc80/lib/python3.12/site-packages (from transformers) (3.18.0)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.30.0 in /Users/lasyayadlapati/miniforge3/envs/dsc80/lib/python3.12/site-packages (from transformers) (0.30.1)\n",
      "Requirement already satisfied: numpy>=1.17 in /Users/lasyayadlapati/miniforge3/envs/dsc80/lib/python3.12/site-packages (from transformers) (1.26.4)\n",
      "Requirement already satisfied: packaging>=20.0 in /Users/lasyayadlapati/miniforge3/envs/dsc80/lib/python3.12/site-packages (from transformers) (24.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /Users/lasyayadlapati/miniforge3/envs/dsc80/lib/python3.12/site-packages (from transformers) (6.0.2)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /Users/lasyayadlapati/miniforge3/envs/dsc80/lib/python3.12/site-packages (from transformers) (2024.11.6)\n",
      "Requirement already satisfied: requests in /Users/lasyayadlapati/miniforge3/envs/dsc80/lib/python3.12/site-packages (from transformers) (2.32.3)\n",
      "Requirement already satisfied: tokenizers<0.22,>=0.21 in /Users/lasyayadlapati/miniforge3/envs/dsc80/lib/python3.12/site-packages (from transformers) (0.21.1)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in /Users/lasyayadlapati/miniforge3/envs/dsc80/lib/python3.12/site-packages (from transformers) (0.5.3)\n",
      "Requirement already satisfied: tqdm>=4.27 in /Users/lasyayadlapati/miniforge3/envs/dsc80/lib/python3.12/site-packages (from transformers) (4.66.5)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /Users/lasyayadlapati/miniforge3/envs/dsc80/lib/python3.12/site-packages (from huggingface-hub<1.0,>=0.30.0->transformers) (2025.3.2)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /Users/lasyayadlapati/miniforge3/envs/dsc80/lib/python3.12/site-packages (from huggingface-hub<1.0,>=0.30.0->transformers) (4.12.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/lasyayadlapati/miniforge3/envs/dsc80/lib/python3.12/site-packages (from requests->transformers) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/lasyayadlapati/miniforge3/envs/dsc80/lib/python3.12/site-packages (from requests->transformers) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/lasyayadlapati/miniforge3/envs/dsc80/lib/python3.12/site-packages (from requests->transformers) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/lasyayadlapati/miniforge3/envs/dsc80/lib/python3.12/site-packages (from requests->transformers) (2024.8.30)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: torch in /Users/lasyayadlapati/miniforge3/envs/dsc80/lib/python3.12/site-packages (2.6.0)\n",
      "Requirement already satisfied: filelock in /Users/lasyayadlapati/miniforge3/envs/dsc80/lib/python3.12/site-packages (from torch) (3.18.0)\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in /Users/lasyayadlapati/miniforge3/envs/dsc80/lib/python3.12/site-packages (from torch) (4.12.2)\n",
      "Requirement already satisfied: networkx in /Users/lasyayadlapati/miniforge3/envs/dsc80/lib/python3.12/site-packages (from torch) (3.3)\n",
      "Requirement already satisfied: jinja2 in /Users/lasyayadlapati/miniforge3/envs/dsc80/lib/python3.12/site-packages (from torch) (3.1.4)\n",
      "Requirement already satisfied: fsspec in /Users/lasyayadlapati/miniforge3/envs/dsc80/lib/python3.12/site-packages (from torch) (2025.3.2)\n",
      "Requirement already satisfied: setuptools in /Users/lasyayadlapati/miniforge3/envs/dsc80/lib/python3.12/site-packages (from torch) (75.1.0)\n",
      "Requirement already satisfied: sympy==1.13.1 in /Users/lasyayadlapati/miniforge3/envs/dsc80/lib/python3.12/site-packages (from torch) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /Users/lasyayadlapati/miniforge3/envs/dsc80/lib/python3.12/site-packages (from sympy==1.13.1->torch) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /Users/lasyayadlapati/miniforge3/envs/dsc80/lib/python3.12/site-packages (from jinja2->torch) (2.1.5)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install sentence_transformers\n",
    "%pip install transformers\n",
    "%pip install torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import GPT2LMHeadModel, GPT2Tokenizer\n",
    "from sentence_transformers import SentenceTransformer\n",
    "import torch\n",
    "\n",
    "# Load models\n",
    "title_gen_model_name = \"gpt2\"\n",
    "embed_model_name = \"sentence-transformers/all-MiniLM-L6-v2\"\n",
    "\n",
    "# GPT-2 tokenizer & model for title generation\n",
    "tokenizer = GPT2Tokenizer.from_pretrained(title_gen_model_name)\n",
    "model = GPT2LMHeadModel.from_pretrained(title_gen_model_name)\n",
    "model.eval()\n",
    "\n",
    "# SentenceTransformer for semantic awareness (optional here but useful if you expand this)\n",
    "embedder = SentenceTransformer(embed_model_name)\n",
    "\n",
    "def generate_title_from_overview(overview, budget=None, release_year=None, max_length=12):\n",
    "    # Create a simple prompt\n",
    "    prompt = f\"Movie Overview: {overview}\\nSuggested Title:\"\n",
    "    \n",
    "    # Tokenize input\n",
    "    inputs = tokenizer(prompt, return_tensors=\"pt\")\n",
    "    input_ids = inputs[\"input_ids\"]\n",
    "\n",
    "    # Generate text\n",
    "    with torch.no_grad():\n",
    "        outputs = model.generate(\n",
    "            input_ids,\n",
    "            max_length=input_ids.shape[1] + max_length,\n",
    "            temperature=0.9,\n",
    "            top_k=50,\n",
    "            top_p=0.95,\n",
    "            do_sample=True,\n",
    "            num_return_sequences=1,\n",
    "            pad_token_id=tokenizer.eos_token_id,\n",
    "        )\n",
    "\n",
    "    # Decode and clean output\n",
    "    generated_text = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "    title = generated_text.split(\"Suggested Title:\")[-1].strip().split(\"\\n\")[0]\n",
    "    \n",
    "    return title"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[df[\"budget\"] != 0]\n",
    "# removing the genres that are not strings\n",
    "df = df[df['genres'].apply(lambda x: isinstance(x, str))]\n",
    "\n",
    "# Step 1: Convert genre strings into lists\n",
    "list_genres = df[\"genres\"].dropna().apply(lambda x: [g.strip() for g in x.split(\",\")])\n",
    "\n",
    "# Step 2: Flatten and collect unique genres\n",
    "unique_genres = set(genre for sublist in list_genres for genre in sublist)\n",
    "\n",
    "# Optional: Sort alphabetically\n",
    "unique_genres = sorted(unique_genres)\n",
    "\n",
    "\n",
    "# Two-Stage Pipeline: Predict Genre, then Predict Revenue using Genre + Emotion + Synopsis\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.multioutput import MultiOutputClassifier\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.preprocessing import MultiLabelBinarizer, StandardScaler\n",
    "from sklearn.metrics import mean_absolute_error, f1_score, accuracy_score, hamming_loss\n",
    "from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer\n",
    "from xgboost import XGBRegressor\n",
    "\n",
    "# ---------------------\n",
    "# 1. Load and Clean Data\n",
    "# ---------------------\n",
    "# Select target genres to simplify\n",
    "selected_genres = ['Action', 'Adventure', 'Comedy', 'Crime', 'Drama', 'Fantasy', 'Romance', 'Science Fiction', 'Thriller']\n",
    "\n",
    "# Parse genres to list\n",
    "df['genre_list'] = df['genres'].apply(lambda x: [g.strip() for g in x.split(',') if g.strip() in selected_genres])\n",
    "\n",
    "# ---------------------\n",
    "# 2. Multi-label Genre Matrix\n",
    "# ---------------------\n",
    "mlb = MultiLabelBinarizer(classes=selected_genres)\n",
    "Y_genres = mlb.fit_transform(df['genre_list'])\n",
    "\n",
    "# ---------------------\n",
    "# 3. Extract Sentiment Feature\n",
    "# ---------------------\n",
    "analyzer = SentimentIntensityAnalyzer()\n",
    "df['sentiment'] = df['overview'].apply(lambda x: analyzer.polarity_scores(str(x))['compound'])\n",
    "\n",
    "# ---------------------\n",
    "# 4. TF-IDF of Synopsis\n",
    "# ---------------------\n",
    "tfidf = TfidfVectorizer(max_features=1000, stop_words='english')\n",
    "X_synopsis = tfidf.fit_transform(df['overview']).toarray()\n",
    "\n",
    "# ---------------------\n",
    "# 5. Stage 1: Genre Prediction\n",
    "# ---------------------\n",
    "X_train_g, X_test_g, y_train_g, y_test_g = train_test_split(X_synopsis, Y_genres, test_size=0.2, random_state=42)\n",
    "\n",
    "genre_model = MultiOutputClassifier(LogisticRegression(max_iter=1000))\n",
    "genre_model.fit(X_train_g, y_train_g)\n",
    "genre_preds = genre_model.predict(X_synopsis)  # Use full set for input to Stage 2\n",
    "\n",
    "# ---------------------\n",
    "# 6. Combine Features for Revenue Model\n",
    "# ---------------------\n",
    "metadata_cols = ['budget', 'release_year']\n",
    "metadata = df[metadata_cols].fillna(0)\n",
    "scaler = StandardScaler()\n",
    "X_metadata = scaler.fit_transform(metadata)\n",
    "\n",
    "X_emotion = df[['sentiment']].values  # Only sentiment for now\n",
    "X_combined = np.hstack([genre_preds, X_emotion, X_synopsis, X_metadata])\n",
    "\n",
    "# ---------------------\n",
    "# 7. Revenue Prediction\n",
    "# ---------------------\n",
    "y_revenue = df['revenue'].values\n",
    "y_log = np.log1p(y_revenue)\n",
    "\n",
    "X_train_rev, X_test_rev, y_train_rev, y_test_rev = train_test_split(X_combined, y_log, test_size=0.2, random_state=42)\n",
    "\n",
    "revenue_model = XGBRegressor()\n",
    "revenue_model.fit(X_train_rev, y_train_rev)\n",
    "\n",
    "# Predict and evaluate\n",
    "log_preds = revenue_model.predict(X_test_rev)\n",
    "revenue_preds = np.expm1(log_preds)\n",
    "revenue_true = np.expm1(y_test_rev)\n",
    "\n",
    "revenue_acc = revenue_model.score(X_test_rev, y_test_rev)\n",
    "print(\"Revenue Accuracy: \", revenue_acc)\n",
    "print(\"\\n💰 Revenue Prediction Results:\")\n",
    "print(\"MAE:\", mean_absolute_error(revenue_true, revenue_preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib\n",
    "joblib.dump(genre_model, \"models/genre_model.pkl\")\n",
    "joblib.dump(revenue_model, \"models/revenue_model.pkl\")\n",
    "joblib.dump(tfidf, \"models/tfidf_vectorizer.pkl\")\n",
    "joblib.dump(scaler, \"models/scaler.pkl\")\n",
    "joblib.dump(mlb, \"models/mlb.pkl\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dsc80",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
